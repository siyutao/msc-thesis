\chapter{Data}\label{chapter:data}

\section{Universal Dependencies}\label{sec:data_ud}

\textbf{Universal Dependencies (UD)} is the main source of primary data used for the present study. It is designed as a cross-linguistically consistent system for annotating morphosyntactic information within a dependency grammar framework \citep{demarneffe2021}. 

The v2 update to the UD annotation guidelines also introduced changes that intend to decrease the reliance on language-specific categories \citep{nivre2020}. Inevitably, these efforts had to be balanced against the practicality of computational efficiency but nevertheless converged in many cases with proposals by typologists, as the core principles converged with a functional typology approach. \citet{croft2017}

\begin{enumerate}
    \item UD needs to be satisfactory on linguistic analysis grounds for individual languages.
    \item UD needs to be good for linguistic typology, i.e., providing a suitable basis for bringing out cross-linguistic parallelism across languages and language families.
    \item UD must be suitable for rapid, consistent annotation by a human annotator.
    \item UD must be easily comprehended and used by a non-linguist, whether a language learner or an engineer with prosaic needs for language processing. We refer to this as seeking a \textit{habitable} design, and it leads us to favor traditional grammar notions and terminology.
    \item UD must be suitable for computer parsing with high accuracy.
    \item UD must support well downstream language understanding tasks (relation extraction, reading comprehension, machine translation, \dots).
\end{enumerate}

See \ref{tab:treebanks} for a table of languages available in UD v2.5, as an example. The thesis uses the UD v2.11 release, which covers 138 languages with 243 treebanks.

\input{figures/ud_languages.tex}

\section{Data selection}\label{sec:data_selection}

For this study, I include only languages with at least 10,000 tokens across the treebanks. Additionally, L2 learner corpora for Chinese, English, Italian and code-switch corpora of Hindi-English and Turkish-German are excluded as out of scope. Korean corpora are also excluded due to the lack of verb lemmatization complicating verb valency research, although they may be added in a later version of this study with the use of an additional lemmatization tool.

In total, 79 languages out of the 138 languages will be used for the experiments and in the experiments further subsets are taken where necessary resulting in a smaller subset.